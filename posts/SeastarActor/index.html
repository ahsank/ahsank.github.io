<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/libs/highlight/styles/github.min.css"> <link rel=stylesheet  href="/css/franklin.css"> <link rel=stylesheet  href="/css/basic.css"> <link rel=icon  href="/assets/favicon.png"> <title>Benchmarking Seastar: Unleashing Asynchronous Performance</title> <header> <div class=blog-name ><a href="/">Ahsan Khan</a></div> <nav> <ul> <li><a href="/">Main</a> <li><a href="/about//">About</a> </ul> <img src="/assets/hamburger.svg" id=menu-icon > </nav> </header> <div class=franklin-content ><h2 id=benchmarking_seastar_unleashing_asynchronous_performance ><a href="#benchmarking_seastar_unleashing_asynchronous_performance" class=header-anchor >Benchmarking Seastar: Unleashing Asynchronous Performance</a></h2> <p>This blog post explores the benefits of Seastar, an asynchronous framework, using our benchmark. Compared to traditional synchronous approaches, Seastar promises significant performance gains.</p> <p><strong>Seastar: Unleashing Parallelism</strong></p> <p>Seastar&#39;s core lies in its asynchronous system design. Each thread owns and guards its data segment, communicating with others through messages. This eliminates the need for locks and unlocks, boosting speed and efficiency.</p> <p><strong>Futures and Continuations: Building Asynchronous Workflows</strong></p> <p>Seastar revolves around two key concepts:</p> <ul> <li><p><strong>Futures:</strong> These represent results waiting to happen, returned by asynchronous functions. You can wait for futures with <code>get&#40;&#41;</code> or chain actions with <code>then&#40;&#41;</code> for a linear, callback-free workflow.</p> <li><p><strong>Continuations:</strong> These allow seamless chaining of actions after a future resolves, eliminating complex nested callbacks and state management.</p> </ul> <p><strong>Seastar Benchmark: Putting Theory into Practice</strong></p> <p>To showcase Seastar&#39;s power, we&#39;ll replicate a previous benchmark conducted with mutex-based synchronization. While Seastar offers a sophisticated Sharded Service for data management, we&#39;ll utilize the lower-level <code>seastar::smp::submit_to&#40;...&#41;</code> to run our <code>calc&#40;cache&#41;</code> function on a dedicated core, ensuring lock-free execution.</p> <p><strong>Benchmark Results: Quantifying the Asynchronous Advantage</strong></p> <table><tr><th align=right >Benchmark<th align=right >Time &#40;ms&#41;<th align=right >CPU &#40;ms&#41;<th align=right >Iterations<tr><td align=right >BM_SeastarHash/8<td align=right >1.22<td align=right >1.22<td align=right >573<tr><td align=right >BM_SeastarHash/64<td align=right >1.25<td align=right >1.25<td align=right >544</table> <p>The results are striking: Seastar outperforms the mutex-based benchmark by an order of magnitude&#33;</p> <p>Following is the snippet of the benchmark code. The build and run instructions can be found in <a href=" https://github.com/ahsank/EvaluateIPC/tree/master/tests/seastar">github repo</a></p> <pre><code class="cpp hljs"><span class=hljs-type >int</span> nshard = std::<span class=hljs-built_in >min</span>(num_tasks, seastar::smp::count);
std::chrono::microseconds sleep_time = std::chrono::<span class=hljs-built_in >microseconds</span>(state.<span class=hljs-built_in >range</span>(<span class=hljs-number >0</span>));
<span class=hljs-keyword >for</span> (<span class=hljs-keyword >auto</span> _ : state) {
    cachetype cache;
    seastar::<span class=hljs-built_in >parallel_for_each</span>(boost::<span class=hljs-built_in >irange</span>(<span class=hljs-number >0u</span>, max_iter),
        [nshard, &amp;cache, sleep_time] (<span class=hljs-type >unsigned</span> f) {
             <span class=hljs-keyword >return</span> seastar::smp::<span class=hljs-built_in >submit_to</span>(<span class=hljs-number >0</span>, [&amp;cache] {
                 <span class=hljs-built_in >calc</span>(cache);
                 <span class=hljs-keyword >return</span> seastar::make_ready_future&lt;&gt;();
             }).<span class=hljs-built_in >then</span>([sleep_time, f, nshard] {
                 <span class=hljs-keyword >return</span> seastar::smp::<span class=hljs-built_in >submit_to</span>(f % nshard, [sleep_time] {
                     <span class=hljs-keyword >return</span> seastar::<span class=hljs-built_in >sleep</span>(sleep_time);
                 });
             }).<span class=hljs-built_in >then</span>([&amp;cache] {
                 <span class=hljs-keyword >return</span> seastar::smp::<span class=hljs-built_in >submit_to</span>(<span class=hljs-number >0</span>, [&amp;cache] {
                     <span class=hljs-built_in >calc</span>(cache);
                     <span class=hljs-keyword >return</span> seastar::make_ready_future&lt;&gt;();
                 });
             });
    }).<span class=hljs-built_in >get</span>();
    <span class=hljs-built_in >checkWork</span>(state, cache);
}</code></pre> <p><strong>Conclusion: Embracing Asynchronous Power</strong></p> <p>Seastar&#39;s innovative architecture and asynchronous approach make it a compelling choice for high-performance server applications. By leveraging its capabilities, developers can unlock exceptional speed and efficiency, shaping the future of lightning-fast applications.</p> <p><strong>Further Exploration:</strong></p> <ul> <li><p>Explore Seastar&#39;s Sharded Service class for efficient multi-core data management.</p> <li><p>Consider Seastar&#39;s high-performance networking options for additional optimization.</p> <li><p>Dive deeper into Seastar&#39;s shared-nothing design for a comprehensive understanding of its architecture.</p> </ul> <div class=page-foot > <a href="http://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a> Ahsan Khan. Last modified: January 03, 2024. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a>. </div> </div> <script src="/libs/highlight/highlight.min.js"></script> <script>hljs.highlightAll();hljs.configure({tabReplace: ' '});</script>